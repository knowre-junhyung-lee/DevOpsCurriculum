# Quest 07. 여러 대의 서버로 서비스 하기

## Introduction
* 이번 퀘스트는 여러 대의 서버를 통해 안정적인 서비스를 만드는 방법을 다룹니다.

## Topics
* Switch
  * L2 Switch
  * L3 Switch
  * L4 Switch
  * L7 Switch
* Load Balancer
  * 리스너
  * 대상그룹
  * 상태 검사

## Resources
* [ELB](https://aws.amazon.com/ko/elasticloadbalancing)
* [Single point of failure](https://en.wikipedia.org/wiki/Single_point_of_failure)

## Checklist
* Single Point of Failure는 어떤 개념일까요?

  * SPOF 단일 실패 지점 이라고 합니다.
어떤 시스템에서 단일 지점에 문제가 생기면 그 시스템이 동작하지 않는 현상이 발생할 수 있습니다.
이렇게 중복성이나 가용성에 대한 조치가 되지 않아 문제가 발생하는 지점을 SPOF 라고 합니다.

* 여러 대의 서버로 서비스할 때의 장점은 무엇일까요? 또 주의해야 할 점은 무엇일까요?

  * SPOF 극복이 가능합니다. 여러대의 서버를 가동함으로써 1대의 서버가 실패하여도 서비스가 동작할 수 있습니다.
또한 서비스의 부하를 분산할 수 있습니다. 여러대의 서버를 수평적으로 확장함으로써 로드의 증가에 대처할 수 있습니다.
주의해야할 점은 여러대의 서버가 같은 데이터를 이용해야 하는 경우와 일부 서버가 동작하지 않는 상황입니다.
웹어플리케이션의 세션과 같은 정보는 여러대의 서버가 공유할 수 있도록 구성해야합니다.
일부 서버가 동작하지 않을 때는 동작하지 않는 서버로 클라이언트가 요청하지 않도록 제외시켜야합니다.
  
* AWS에서 제공하는 로드밸런서에는 어떤 종류가 있나요? 각각의 용도는 무엇일까요?
  
  * ALB : L7 에서 동작하는 로드밸런서입니다. 주로 HTTP 프로토콜에 대한 세부적인 설정이 가능합니다. 헤더를 이용한 경로 배정이나 SSL 암복호화 등이 가능합니다.
  
  * ELB : L4 에서 동작하는 로드밸런서입니다. 주로 TCP, UDP 프로토콜에 대한 설정이 가능합니다. 어플리케이션 계층의 프로토콜을 조작하지 못 합니다. 
L4 까지의 프로토콜을 다루기 때문에 ALB 보다 상대적으로 트래픽 처리가 빠릅니다.
웹어플리케이션은 물론 TCP, UDP 를 사용하는 다른 서비스 들에도 적용이 가능합니다. 빠른 속도를 요하는 서비스에 적합합니다.
  
  * CLB : ALB 와 NLB 가 출시되기 전에 존재한 로드밸런서입니다.
L4 와 L7 에 대한 설정이 모두 가능 했지만 각 계층에 더욱 특화된 로드밸런서가 출시된 후 사용이 줄어들고 있습니다. 2022년에 지원을 종료한다고 합니다.
  
  * GWLB : third-party 어플라이언스에 대한 로드밸런싱을 제공하는 서비스입니다. 보안 어플라이언스를 통해 앞단에서 보호 기능을 제공하고자 할 때 게이트웨이 역할을 합니다.
다른 로드밸런서에 연결하거나 트래픽을 전달할 수 있어서 다양한 보안서비스를 사용할 수 있습니다.
  
* AWS 로드밸런서의 리스너 규칙을 이용해 어떤 일들을 할 수 있을까요?

  * 리스너 규칙은 입력으로 들어오는 파라미터에 대한 응답 방식을 설정할 수 있습니다.
입력으로는 호스트 헤더, 경로, HTTP 헤더 ,HTTP 메소드, 쿼리 문자열, 소스 IP 등이 있습니다.
해당 입력 파라미터에 대한 응답으로 요청을 전달하거나 리디렉션, 고정응답을 정의할 수 있습니다.
리스너 규칙을 통해서 HTTP 요청을 HTTPS 로 리디렉션하거나 여러 어플리케이션이 경로를 통해 연결될 수 있습니다.

* AWS의 여러 리전(서울, 도쿄 등)으로 로드밸런싱을 하는 것도 가능할까요?

  * 첫번째, AWS 의 Global Accelerator 를 통해서 리전 간 로드밸런싱이 가능합니다.
두번째, Route53 서비스를 통해 DNS 레코드를 여러 리전의 공인 IP 에 설정하는 방법이 있습니다.
  
## Quest
* EC2 인스턴스를 한 대 더 늘리고, 앞단에 ELB를 사용하여 두 대를 로드밸런싱 해 보세요. 직전 퀘스트에서 만들었던 컨테이너를 이용하시면 됩니다.
* 두 대의 서버 모두에 번갈아 요청이 들어오는지 확인해 보세요.
* 만약 한 대의 서버의 컨테이너를 내렸을 때, 자동으로 나머지 한 대의 서버로만 요청이 가게 되도록 설정해 보세요. Application Load Balancer를 이용해서 구현해 봅시다!

## Advanced
* Sticky Session이란 어떤 개념일까요?
